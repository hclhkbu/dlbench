WorkDir=.
OutputDir = "$WorkDir$/Output"
ModelDir = "$OutputDir$/Models"
DataDir = "HOME/data/cntk/cifar10"
#DataDir = "/home/comp/pengfeixu/Data/cntk/cifar10"

precision=float
deviceId=1
minibatchSize=64
epochSize=50000
maxEpochs=40

command=Train:Test

makeMode=false
distributedMBReading=false

initOnCPUOnly=true

imageLayout="cudnn"
prefetch=true

traceLevel=1
shareNodeValueMatrices=true
#maxTempMemSizeInSamplesForCNN=1

modelPath=$ModelDir$/alexnet_cifar10

Train=[
    action=train
    BrainScriptNetworkBuilder = {
        imageShape = 32:32:3
        labelDim = 10
        
        MyConvLayer(inp, outMap, inMap, kW, kH, hStride, vStride, wScale, bValue, pad) =
        { 
            W = Parameter (outMap, inMap * kW * kH, init="gaussian", initValueScale=wScale)
            b = Parameter (outMap, 1, init="fixedValue", value=bValue)
            c = Convolution (W, inp, (kW:kH:inMap), stride=(hStride:vStride:inMap), lowerPad=(pad:pad:0), upperPad=(pad:pad:0))
            y = c + b
            #y = RectifiedLinear (c + b)
        }.y

        model (features) = {
            featNorm = features # - 128
            #conv1 = ConvolutionalLayer {32, (5:5), stride=(1:1), pad=true, lowerPad=(2:2), upperPad=(2:2), initValueScale=0.1557/256} (featNorm)
            # Input Size: 32*32*3
            conv1 = ConvolutionalLayer {32, (5:5), stride=(1:1), pad=true, lowerPad=(2:2), upperPad=(2:2), init="gaussian", initValueScale=2.7716} (featNorm)
            pool1 = MaxPoolingLayer {(3:3), stride=(2:2)} (conv1)
            relu1 = RectifiedLinear(pool1)
            norm1 = BatchNormalizationLayer {spatialRank = 2} (relu1)

            #conv2 = ConvolutionalLayer {32, (5:5), stride=(1:1), pad=true, lowerPad=(2:2), upperPad=(2:2), initValueScale=0.1557/256} (norm1)
            # Input Size: 15*15 
            conv2 = ConvolutionalLayer {32, (5:5), stride=(1:1), pad=true, lowerPad=(2:2), upperPad=(2:2), init="gaussian", initValueScale=0.75} (norm1)
            pool2 = MaxPoolingLayer {(3:3), stride=(2:2)} (conv2)
            relu2 = RectifiedLinear(pool2)
            norm2 = BatchNormalizationLayer {spatialRank = 2} (relu2)

            #conv3 = ConvolutionalLayer {64, (5:5), stride=(1:1), pad=true, lowerPad=(2:2), upperPad=(2:2), initValueScale=0.1557/256} (norm2)
            # Input Size: 7*7 
            conv3 = ConvolutionalLayer {64, (5:5), stride=(1:1), pad=true, lowerPad=(2:2), upperPad=(2:2), init="gaussian", initValueScale=0.35} (norm2)
            relu3 = RectifiedLinear(conv3)
            pool3 = AveragePoolingLayer {(3:3), stride=(2:2)} (relu3)

            #z  = LinearLayer {10, initValueScale=0.212} (pool3)
            # Input Size: 3*3 
            z  = LinearLayer {10, initValueScale=0.15} (pool3)

            #featNorm = features
            #l1 = ConvolutionalLayer {32, (5:5), pad=true, activation=ReLU, initValueScale=0.1557/256} (featNorm)
            #p1 = MaxPoolingLayer {(3:3), stride=(2:2)} (l1)
            #l2 = ConvolutionalLayer {32, (5:5), pad=true, activation=ReLU, initValueScale=0.2} (p1)
            #p2 = MaxPoolingLayer {(3:3), stride=(2:2)} (l2)
            #l3 = ConvolutionalLayer {64, (5:5), pad=true, activation=ReLU, initValueScale=0.2} (p2)
            #p3 = MaxPoolingLayer {(3:3), stride=(2:2)} (l3)
            #d1 = DenseLayer {64, activation=ReLU, initValueScale=1.697} (p3)
            #z  = LinearLayer {10, initValueScale=0.212} (d1)
        }.z

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
        ce       = CrossEntropyWithSoftmax (labels, z)
        errs     = ClassificationError     (labels, z)

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (z)
    }
    
    SGD=[
        epochSize=$epochSize$
        minibatchSize=$minibatchSize$
        maxEpochs=$maxEpochs$
        learningRatesPerMB=0.01
        #learningRatesPerMB=0.05
        momentumPerMB=0.9
        dropoutRate=0
	    numMBsToShowResult=100

        parallelTrain=[
            parallelizationMethod="DataParallelSGD"
            #distributedMBReading=true
            distributedMBReading=$distributedMBReading$
            parallelizationStartEpoch=1
            dataParallelSGD=[
                gradientBits=4
            ]
        ]

    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        # See REAMDE.md for details on getting the data (Train_cntk_text.txt).
        file = "$DataDir$/Train_cntk_text.txt"
        #randomize=false
        #file = "$DataDir$/train_map.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]
]

Test = [
    action = "test"
    # Set minibatch size for testing.
    minibatchSize = 32 
    epochSize = 10000

    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Test_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
]
